# UT_MachineLearning_I
This repo includes the practice sessions&amp;homeworks of the machine learning course taught in University of Tartu, Fall 2020. The course also included a term project done in groups, you can find it here.

To be very concise, Machine Learning I introduced:

  - Commonly used traditional machine learning algorithms, both for supervised and unsupervised learning problems
  - Basics of Neural Networks
  - Ensemble models
  - Commonly encountered problems in a data project, like overfitting, and ways to deal with them
  - Various metrics for classification problems, mostly useful for unbalanced datasets

## Homeworks Description

  1. Supervised Learning: Implementation of K-Nearest Neighbors, Exploratory Data Analysis, Linear Regression, Decision Trees, Intro to Kaggle, implementation of cross-validation algorithm.
  
  2. Unsupervised Learning: Understanding the concept "Curse of Dimensionality", PCA on MNIST, Hiearchical Clustering, K-Means Clustering, implementation of Elbow Method, t-SNE, t-SNE vs PCA.
  
  3. Deep Learning: Basics of feed-forward neural networks, backpropagation, three layer neural network from scratch, CNNs using KERAS on MNIST, Batch Normalization, practice with fast.ai library, comparison of the performance of 3-layer neural network vs a random forest classifier.
  
  4. Regularization: Meaning of L1 & L2 regularization methods, comparison of ridge&lasso&elasticnet regression, dropout layer&data augmentation for neural networks.
  
  5. Ensemble Learning: Basic&Weighted Ensembles, implementation of bagging, random forests, gradient boosting methods, practice with XGBoost, stacking&blending.
  
  6. Performance Metrics: Accuracy vs F1 Score, precision & recall metrics from scratch, roc curve & auc metric on unbalanced data.
 
